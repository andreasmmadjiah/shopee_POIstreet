{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:16:20.402995Z",
     "start_time": "2021-03-18T03:16:15.302604Z"
    },
    "id": "i5K8aIW1GKYP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:16:20.456016Z",
     "start_time": "2021-03-18T03:16:20.404038Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D, Input\n",
    "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:16:21.400392Z",
     "start_time": "2021-03-18T03:16:20.457017Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn-crfsuite\n",
    "# !pip install seqeval\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:16:21.598231Z",
     "start_time": "2021-03-18T03:16:21.403816Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow_addons.layers.crf import CRF\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras_contrib.layers import CRF\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from crf import CRF\n",
    "# !pip install tf2crf\n",
    "# from tf2CRF import CRF\n",
    "\n",
    "# from tf2crf import CRF, ModelWithCRFLoss\n",
    "# from keras_contrib.metrics import crf_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:17:10.427241Z",
     "start_time": "2021-03-17T14:17:10.424239Z"
    }
   },
   "source": [
    "# Pretrained Bert try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:16:22.665231Z",
     "start_time": "2021-03-18T03:16:21.599235Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from transformers import BertTokenizer, AutoModel\n",
    "from transformers import TFAutoModel\n",
    "from transformers import TFBertModel\n",
    "from transformers import AutoTokenizer,AutoModelForTokenClassification,TFAutoModelForTokenClassification\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-large-p2\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-lite-large-p2\")\n",
    "# model = AutoModel.from_pretrained(\"indobenchmark/indobert-large-p2\")\n",
    "# TFPreTrainedModel.from_pretrained(\"indobenchmark/indobert-large-p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:12:37.640785Z",
     "start_time": "2021-03-18T03:12:37.636771Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import file_utils\n",
    "# print(file_utils.default_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:52:43.221238Z",
     "start_time": "2021-03-18T03:52:43.216238Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"cahya/xlm-roberta-large-indonesian-NER\")\n",
    "# model = AutoModelForTokenClassification.from_pretrained('cahya/xlm-roberta-large-indonesian-NER')\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.569904Z",
     "start_time": "2021-03-18T02:22:52.567900Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = TFBertModel.from_pretrained(\"indobenchmark/indobert-large-p2\")\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T03:15:21.109840Z",
     "start_time": "2021-03-18T03:15:21.101866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.576902Z",
     "start_time": "2021-03-18T02:22:52.571903Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import torch\n",
    "# word = 'karawaci baru, kakap raya 156 rt 1 rw 3 karawaci wongosari'\n",
    "# x = tokenizer.encode(word) \n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.584902Z",
     "start_time": "2021-03-18T02:22:52.579901Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.predict(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.592932Z",
     "start_time": "2021-03-18T02:22:52.586931Z"
    }
   },
   "outputs": [],
   "source": [
    "# a= tokenizer.convert_ids_to_tokens(tokenizer.encode(word))\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.599938Z",
     "start_time": "2021-03-18T02:22:52.593935Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer.convert_tokens_to_ids('[PAD]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add tokenized label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.607937Z",
     "start_time": "2021-03-18T02:22:52.600940Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "if '###asd' in string.punctuation:\n",
    "    print('yeah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.620904Z",
     "start_time": "2021-03-18T02:22:52.608935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['karawaci', 'baru,', 'kakap', 'raya', '156', 'rt', '1', 'rw', '3', 'karawaci', 'wongosari']\n",
      "['B-street', 'I-street', 'O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-street', 'I-street', 'I-street', 'O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "word = 'karawaci baru, kakap raya 156 rt 1 rw 3 karawaci wongosari'\n",
    "x = tokenizer.encode(word)\n",
    "\n",
    "\n",
    "def fix_label(list1,label,raw):\n",
    "    label_fix = []\n",
    "    enumerate_s = 0\n",
    "    enumerate_label = 0\n",
    "    for x in list1:\n",
    "        if (('[' in x) or (x in string.punctuation) or ('#' in x)) and (x not in ['[CLS]','[PAD]','[SEP]']):\n",
    "#             print('wo'+ x)\n",
    "            if 'B' in label_fix[-1]:\n",
    "                label_fix.append(label_fix[-1].replace('B','I'))\n",
    "            else:\n",
    "                label_fix.append(label_fix[-1])\n",
    "        elif x in ['[CLS]','[SEP]','[UNK]','[PAD]']:\n",
    "            label_fix.append('O')\n",
    "        else:\n",
    "            try:\n",
    "                label_fix.append(label[enumerate_label])\n",
    "            except Exception as e:\n",
    "                raise Exception('An error occurred')\n",
    "                \n",
    "        if x not in ['[CLS]','[SEP]','[UNK]','[PAD]']:\n",
    "            enumerate_s+=len(x.strip().replace('#',''))\n",
    "#             print(x,enumerate_s,len(raw.split(' ')[enumerate_label]))\n",
    "            if enumerate_s==len(raw.split(' ')[enumerate_label]):\n",
    "                enumerate_s = 0\n",
    "                enumerate_label += 1\n",
    "        \n",
    "    return label_fix\n",
    "\n",
    "label = ['B-street','I-street','O','B-street','O','O','O','O','O','O','O','O']\n",
    "print(word.split(' '))\n",
    "print(label)\n",
    "# print(a)\n",
    "print(fix_label([tokenizer.convert_ids_to_tokens(x1) for x1 in x],label,word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.628938Z",
     "start_time": "2021-03-18T02:22:52.621905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "23 23\n"
     ]
    }
   ],
   "source": [
    "word = 'kampung.gudang areng,desa:anyer, kecamatan:anyar, kabupaten: serang, belakang bca anyar'\n",
    "word_token = ['[CLS]', 'kampung', '.', 'gudang', 'aren', '##g', ',', 'desa', ':', 'anyer', ',', 'kecamatan', ':', 'anyar', ',', 'kabupaten', ':', 'serang', ',', 'belakang', 'bca', 'anyar', '[SEP]']\n",
    "label = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "print(fix_label(word_token,label,word))\n",
    "print(len(fix_label(word_token,label,word)),len(word_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.638900Z",
     "start_time": "2021-03-18T02:22:52.630903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'kampung', '.', 'gudang', 'aren', '##g', ',', 'desa', ':', 'anyer', ',', 'kecamatan', ':', 'anyar', ',', 'kabupaten', ':', 'serang', ',', 'belakang', 'bca', 'anyar', '[SEP]']\n",
      "['O', 'B-street', 'I-street', 'I-street', 'B-street', 'I-street', 'I-street', 'B-street', 'I-street', 'B-street', 'I-street', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "23 23\n"
     ]
    }
   ],
   "source": [
    "word = 'kampung. gudang areng,desa:anyer, kecamatan:anyar, kabupaten: serang, belakang bca anyar'\n",
    "# word_token = ['[CLS]', 'kampung', '.', 'gudang', 'aren', '##g', ',', 'desa', ':', 'anyer', ',', 'kecamatan', ':', 'anyar', ',', 'kabupaten', ':', 'serang', ',', 'belakang', 'bca', 'anyar', '[SEP]']\n",
    "word_token = tokenizer.convert_ids_to_tokens(tokenizer.encode(word))\n",
    "label = ['B-street', 'I-street', 'B-street', 'O', 'O', 'O', 'O', 'O','O']\n",
    "print(word_token)\n",
    "print(fix_label(word_token,label,word))\n",
    "print(len(fix_label(word_token,label,word)),len(word_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:52.645932Z",
     "start_time": "2021-03-18T02:22:52.640903Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:53.141847Z",
     "start_time": "2021-03-18T02:22:52.647906Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "0814LcuSGVDC",
    "outputId": "bcf6f3ca-7a4f-499f-c120-d0561aed845a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>/jl kapuk timur delta sili iii lippo cika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>/siung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>toko dita/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>/jl. orde baru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        raw_address  \\\n",
       "0   0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1   1                                 aye, jati sampurna   \n",
       "2   2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3   3                               toko dita, kertosono   \n",
       "4   4                                      jl. orde baru   \n",
       "\n",
       "                                  POI/street  \n",
       "0  /jl kapuk timur delta sili iii lippo cika  \n",
       "1                                          /  \n",
       "2                                     /siung  \n",
       "3                                 toko dita/  \n",
       "4                             /jl. orde baru  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:22:53.207874Z",
     "start_time": "2021-03-18T02:22:53.144842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "ic-_6IAFGi_F",
    "outputId": "d3eaf4ed-8b52-41d5-8245-b871a7421934"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    raw_address\n",
       "0   0          s. par 53 sidanegara 4 cilacap tengah\n",
       "1   1          angg per, baloi indah kel. lubuk baja\n",
       "2   2                          asma laun, mand imog,\n",
       "3   3  ud agung rej, raya nga sri wedari karanganyar\n",
       "4   4                     cut mutia, 35 baiturrahman"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:51:41.262826Z",
     "start_time": "2021-03-18T05:51:40.340272Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "vUkhehRxGjNK",
    "outputId": "7751a984-3947-4306-bd61-0e20849a701b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>street</th>\n",
       "      <th>raw_split</th>\n",
       "      <th>street_split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika</td>\n",
       "      <td>['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...</td>\n",
       "      <td>['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...</td>\n",
       "      <td>['B-street', 'I-street', 'I-street', 'I-street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['aye,', 'jati', 'sampurna']</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>siung</td>\n",
       "      <td>['setu', 'siung', '119', 'rt', '5', '1', '1388...</td>\n",
       "      <td>['siung']</td>\n",
       "      <td>['O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['toko', 'dita,', 'kertosono']</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>['jl.', 'orde', 'baru']</td>\n",
       "      <td>['jl.', 'orde', 'baru']</td>\n",
       "      <td>['B-street', 'I-street', 'I-street']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1                                 aye, jati sampurna   \n",
       "2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3                               toko dita, kertosono   \n",
       "4                                      jl. orde baru   \n",
       "\n",
       "                                     street  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika   \n",
       "1                                       NaN   \n",
       "2                                     siung   \n",
       "3                                       NaN   \n",
       "4                             jl. orde baru   \n",
       "\n",
       "                                           raw_split  \\\n",
       "0  ['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...   \n",
       "1                       ['aye,', 'jati', 'sampurna']   \n",
       "2  ['setu', 'siung', '119', 'rt', '5', '1', '1388...   \n",
       "3                     ['toko', 'dita,', 'kertosono']   \n",
       "4                            ['jl.', 'orde', 'baru']   \n",
       "\n",
       "                                        street_split  \\\n",
       "0  ['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...   \n",
       "1                                               ['']   \n",
       "2                                          ['siung']   \n",
       "3                                               ['']   \n",
       "4                            ['jl.', 'orde', 'baru']   \n",
       "\n",
       "                                               label  \n",
       "0  ['B-street', 'I-street', 'I-street', 'I-street...  \n",
       "1                                    ['O', 'O', 'O']  \n",
       "2    ['O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O']  \n",
       "3                                    ['O', 'O', 'O']  \n",
       "4               ['B-street', 'I-street', 'I-street']  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_label = pd.read_csv('data_train_label.csv')\n",
    "data_train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:51:49.122577Z",
     "start_time": "2021-03-18T05:51:41.955518Z"
    },
    "id": "p9U85hTqIezb"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "# list_y = data_train_label['label'].apply(lambda x: ast.literal_eval(x)).values\n",
    "\n",
    "data_train_label['label'] = data_train_label['label'].apply(lambda x: ast.literal_eval(x)).values\n",
    "data_train_label['raw_split'] = data_train_label['raw'].apply(lambda x: [x1 for x1 in x.split(' ') if x1!='']).values\n",
    "list_x = data_train_label['raw_split'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T05:53:02.586647Z",
     "start_time": "2021-03-18T05:53:02.437483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>street</th>\n",
       "      <th>raw_split</th>\n",
       "      <th>street_split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kampung.gudang areng,desa:anyer, kecamatan:any...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[kampung.gudang, areng,desa:anyer,, kecamatan:...</td>\n",
       "      <td>['']</td>\n",
       "      <td>[O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  raw street  \\\n",
       "15  kampung.gudang areng,desa:anyer, kecamatan:any...    NaN   \n",
       "\n",
       "                                            raw_split street_split  \\\n",
       "15  [kampung.gudang, areng,desa:anyer,, kecamatan:...         ['']   \n",
       "\n",
       "                       label  \n",
       "15  [O, O, O, O, O, O, O, O]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_label[data_train_label['raw_split'].apply(lambda x: x[0]).isin(['kampung.gudang'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:23:02.812366Z",
     "start_time": "2021-03-18T02:23:00.132191Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_label['street_split'] = data_train_label['street_split'].apply(lambda x: ast.literal_eval(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:23:57.536545Z",
     "start_time": "2021-03-18T02:23:02.814341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "X = [tokenizer.encode(x1) for x1 in data_train_label['raw'].values.tolist()]\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:23:57.541506Z",
     "start_time": "2021-03-18T02:23:57.537504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1637, 1012, 70, 1276, 16691, 18946, 4100, 20744, 6484, 29832, 1113, 253, 8019, 88, 10320, 1417, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[0])\n",
    "len(data_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:23:57.556469Z",
     "start_time": "2021-03-18T02:23:57.544470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>street</th>\n",
       "      <th>raw_split</th>\n",
       "      <th>street_split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, ci...</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, cika]</td>\n",
       "      <td>[B-street, I-street, I-street, I-street, I-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[aye,, jati, sampurna]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>siung</td>\n",
       "      <td>[setu, siung, 119, rt, 5, 1, 13880, cipayung]</td>\n",
       "      <td>[siung]</td>\n",
       "      <td>[O, B-street, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[toko, dita,, kertosono]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[B-street, I-street, I-street]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1                                 aye, jati sampurna   \n",
       "2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3                               toko dita, kertosono   \n",
       "4                                      jl. orde baru   \n",
       "\n",
       "                                     street  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika   \n",
       "1                                       NaN   \n",
       "2                                     siung   \n",
       "3                                       NaN   \n",
       "4                             jl. orde baru   \n",
       "\n",
       "                                           raw_split  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, ci...   \n",
       "1                             [aye,, jati, sampurna]   \n",
       "2      [setu, siung, 119, rt, 5, 1, 13880, cipayung]   \n",
       "3                           [toko, dita,, kertosono]   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                        street_split  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, cika]   \n",
       "1                                                 []   \n",
       "2                                            [siung]   \n",
       "3                                                 []   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                               label  \n",
       "0  [B-street, I-street, I-street, I-street, I-str...  \n",
       "1                                          [O, O, O]  \n",
       "2                    [O, B-street, O, O, O, O, O, O]  \n",
       "3                                          [O, O, O]  \n",
       "4                     [B-street, I-street, I-street]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:00.614313Z",
     "start_time": "2021-03-18T02:23:57.557468Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "data_train_label['raw_token'] = copy.deepcopy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:03.974294Z",
     "start_time": "2021-03-18T02:24:00.615299Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_label['raw_token_word'] = [[tokenizer.convert_ids_to_tokens(x12) for x12 in x1] for x1 in data_train_label['raw_token'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:06.492750Z",
     "start_time": "2021-03-18T02:24:03.975288Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "X_backup = copy.deepcopy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:06.497690Z",
     "start_time": "2021-03-18T02:24:06.493731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:18.538073Z",
     "start_time": "2021-03-18T02:24:06.498690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>street</th>\n",
       "      <th>raw_split</th>\n",
       "      <th>street_split</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_token</th>\n",
       "      <th>raw_token_word</th>\n",
       "      <th>label_fix_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, ci...</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, cika]</td>\n",
       "      <td>[B-street, I-street, I-street, I-street, I-str...</td>\n",
       "      <td>[2, 1637, 1012, 70, 1276, 16691, 18946, 4100, ...</td>\n",
       "      <td>[[CLS], jl, kap, ##uk, timur, delta, sili, iii...</td>\n",
       "      <td>[O, B-street, I-street, I-street, I-street, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[aye,, jati, sampurna]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[2, 675, 29835, 29946, 4868, 372, 2951, 3]</td>\n",
       "      <td>[[CLS], ay, ##e, ,, jati, samp, ##urna, [SEP]]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>siung</td>\n",
       "      <td>[setu, siung, 119, rt, 5, 1, 13880, cipayung]</td>\n",
       "      <td>[siung]</td>\n",
       "      <td>[O, B-street, O, O, O, O, O, O]</td>\n",
       "      <td>[2, 332, 29838, 27505, 17689, 4345, 418, 111, ...</td>\n",
       "      <td>[[CLS], set, ##u, siung, 119, rt, 5, 1, 138, #...</td>\n",
       "      <td>[O, O, O, B-street, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[toko, dita,, kertosono]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[2, 1605, 18154, 29946, 21309, 7551, 1867, 3]</td>\n",
       "      <td>[[CLS], toko, dita, ,, kert, ##oso, ##no, [SEP]]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[B-street, I-street, I-street]</td>\n",
       "      <td>[2, 1637, 29948, 9057, 440, 3]</td>\n",
       "      <td>[[CLS], jl, ., orde, baru, [SEP]]</td>\n",
       "      <td>[O, B-street, I-street, I-street, I-street, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1                                 aye, jati sampurna   \n",
       "2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3                               toko dita, kertosono   \n",
       "4                                      jl. orde baru   \n",
       "\n",
       "                                     street  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika   \n",
       "1                                       NaN   \n",
       "2                                     siung   \n",
       "3                                       NaN   \n",
       "4                             jl. orde baru   \n",
       "\n",
       "                                           raw_split  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, ci...   \n",
       "1                             [aye,, jati, sampurna]   \n",
       "2      [setu, siung, 119, rt, 5, 1, 13880, cipayung]   \n",
       "3                           [toko, dita,, kertosono]   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                        street_split  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, cika]   \n",
       "1                                                 []   \n",
       "2                                            [siung]   \n",
       "3                                                 []   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                               label  \\\n",
       "0  [B-street, I-street, I-street, I-street, I-str...   \n",
       "1                                          [O, O, O]   \n",
       "2                    [O, B-street, O, O, O, O, O, O]   \n",
       "3                                          [O, O, O]   \n",
       "4                     [B-street, I-street, I-street]   \n",
       "\n",
       "                                           raw_token  \\\n",
       "0  [2, 1637, 1012, 70, 1276, 16691, 18946, 4100, ...   \n",
       "1         [2, 675, 29835, 29946, 4868, 372, 2951, 3]   \n",
       "2  [2, 332, 29838, 27505, 17689, 4345, 418, 111, ...   \n",
       "3      [2, 1605, 18154, 29946, 21309, 7551, 1867, 3]   \n",
       "4                     [2, 1637, 29948, 9057, 440, 3]   \n",
       "\n",
       "                                      raw_token_word  \\\n",
       "0  [[CLS], jl, kap, ##uk, timur, delta, sili, iii...   \n",
       "1     [[CLS], ay, ##e, ,, jati, samp, ##urna, [SEP]]   \n",
       "2  [[CLS], set, ##u, siung, 119, rt, 5, 1, 138, #...   \n",
       "3   [[CLS], toko, dita, ,, kert, ##oso, ##no, [SEP]]   \n",
       "4                  [[CLS], jl, ., orde, baru, [SEP]]   \n",
       "\n",
       "                                     label_fix_token  \n",
       "0  [O, B-street, I-street, I-street, I-street, I-...  \n",
       "1                           [O, O, O, O, O, O, O, O]  \n",
       "2     [O, O, O, B-street, O, O, O, O, O, O, O, O, O]  \n",
       "3                           [O, O, O, O, O, O, O, O]  \n",
       "4     [O, B-street, I-street, I-street, I-street, O]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_label['label_fix_token'] = data_train_label[['raw','raw_token_word','label']].apply(lambda x: fix_label(x.raw_token_word,x.label,x.raw),axis=1)\n",
    "data_train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:24.330052Z",
     "start_time": "2021-03-18T02:24:18.539084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [raw, street, raw_split, street_split, label, raw_token, raw_token_word, label_fix_token, check]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def check_token_label(df2):\n",
    "    df= df2.copy()\n",
    "    df['check'] = df[['raw_token_word','label_fix_token']].apply(lambda x: len(x.raw_token_word)==len(x.label_fix_token),axis=1)\n",
    "    print(df[df['check']==False])\n",
    "check_token_label(data_train_label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:24.503180Z",
     "start_time": "2021-03-18T02:24:24.331188Z"
    },
    "id": "ySR7hricKkbA"
   },
   "outputs": [],
   "source": [
    "# data_train_label['label_join'] = [' '.join(x) for x in list_y]\n",
    "\n",
    "\n",
    "list_y_token = data_train_label['label_fix_token'].values.tolist()\n",
    "data_train_label['label_join_token'] = [' '.join(x) for x in list_y_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:24.808182Z",
     "start_time": "2021-03-18T02:24:24.504183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['mayor', 'madm', 'hasi', '42', 'rt', '4', '4', 'margahayu', 'bekasi', 'timur']),\n",
       "       list(['B-street', 'I-street', 'I-street', 'O', 'O', 'O', 'O', 'O', 'O', 'O']),\n",
       "       list(['[CLS]', 'mayor', 'mad', '##m', 'has', '##i', '42', 'rt', '4', '4', 'marga', '##ha', '##yu', 'bekasi', 'timur', '[SEP]']),\n",
       "       list(['O', 'B-street', 'I-street', 'I-street', 'I-street', 'I-street', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "data_train_label[['raw_split','label','raw_token_word','label_fix_token']].values[random.randint(0,len(data_train_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:24.816150Z",
     "start_time": "2021-03-18T02:24:24.810185Z"
    },
    "id": "Aaf1Ai7NKRju"
   },
   "outputs": [],
   "source": [
    "# raw_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')  # the filters ='' so that keras doesnot remove any punctuation in our data\n",
    "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:26.553128Z",
     "start_time": "2021-03-18T02:24:24.820176Z"
    },
    "id": "FPqjWWAxKTJt"
   },
   "outputs": [],
   "source": [
    "# raw data train and test concat so that there is no word that does not have index\n",
    "target_data = data_train_label['label_join_token'].values\n",
    "target_tokenizer.fit_on_texts(target_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:26.559073Z",
     "start_time": "2021-03-18T02:24:26.555042Z"
    }
   },
   "outputs": [],
   "source": [
    "tag2idx = {}\n",
    "for key in target_tokenizer.word_index.keys():\n",
    "    tag2idx[key] = target_tokenizer.word_index[key]\n",
    "\n",
    "idx2tag = {}\n",
    "for key in target_tokenizer.index_word.keys():\n",
    "    idx2tag[key] = target_tokenizer.index_word[key]\n",
    "idx2tag\n",
    "\n",
    "tag2idx['PAD'] = 0\n",
    "idx2tag[0]='PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:28.017841Z",
     "start_time": "2021-03-18T02:24:26.561039Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkluEJPcLBxz",
    "outputId": "f95df97b-6703-452a-9abb-41fe4ab1cf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    2  1637  1012    70  1276 16691 18946  4100 20744  6484 29832  1113\n",
      "    253  8019    88 10320  1417     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    2   675 29835 29946  4868   372  2951     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [    2   332 29838 27505 17689  4345   418   111 20092  3193  5908 21562\n",
      "      3     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Add 0 padding so all data has the same length\n",
    "X_pad = tf.keras.preprocessing.sequence.pad_sequences(X,padding='post',value=tokenizer.convert_tokens_to_ids('[PAD]'))\n",
    "print(X_pad[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:28.024803Z",
     "start_time": "2021-03-18T02:24:28.019804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:30.777501Z",
     "start_time": "2021-03-18T02:24:28.026803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "data_target_in = [[tag2idx[w] for w in s] for s in list_y_token]\n",
    "\n",
    "y_pad = tf.keras.preprocessing.sequence.pad_sequences(data_target_in,padding='post',value=tag2idx['PAD'])\n",
    "print(y_pad[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:30.782470Z",
     "start_time": "2021-03-18T02:24:30.778504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_target_in[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:30.792490Z",
     "start_time": "2021-03-18T02:24:30.783472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:33.784690Z",
     "start_time": "2021-03-18T02:24:30.793488Z"
    },
    "id": "JcWFMOYeLxCa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tag2idx)\n",
    "# n_tags\n",
    "y_pad = [to_categorical(i, num_classes=n_tags) for i in y_pad]\n",
    "y_pad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:33.790680Z",
     "start_time": "2021-03-18T02:24:33.786681Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_fix_train = pd.DataFrame({'X':X_pad.tolist(),'y':y_pad})\n",
    "# data_fix_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:33.803671Z",
     "start_time": "2021-03-18T02:24:33.793650Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_fix_train.to_csv('data_fix_train_street.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:34.064497Z",
     "start_time": "2021-03-18T02:24:33.807651Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_pad, test_size=0.15,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:34.072414Z",
     "start_time": "2021-03-18T02:24:34.067418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255000, 47)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:34.083405Z",
     "start_time": "2021-03-18T02:24:34.076423Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install numba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:34.093440Z",
     "start_time": "2021-03-18T02:24:34.085405Z"
    }
   },
   "outputs": [],
   "source": [
    "# from numba import cuda \n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:34.101406Z",
     "start_time": "2021-03-18T02:24:34.097431Z"
    }
   },
   "outputs": [],
   "source": [
    "target_vocab_size = len(idx2tag)\n",
    "max_len = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:34.124434Z",
     "start_time": "2021-03-18T02:24:34.104435Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_ = Input(shape=(max_len,),dtype=tf.int32)\n",
    "    bert = TFBertModel.from_pretrained(\"indobenchmark/indobert-lite-large-p2\")\n",
    "    model = bert(input_)[0]\n",
    "\n",
    "    model = Bidirectional(LSTM(units=150, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "    model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
    "    model = Dense(n_tags)(model)\n",
    "    crf = CRF(n_tags)\n",
    "    out = crf(model)\n",
    "    model = Model(input_, out)\n",
    "#     print(model.summary())\n",
    "#     for layer in model.get_layer('tf_bert_model').layers:\n",
    "#         layer.trainable=False\n",
    "#     for w in model.get_layer('tf_bert_model').weights:\n",
    "#         w._trainable=False\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "    model.compile(optimizer=\"rmsprop\", loss= crf.loss, metrics=[crf.accuracy])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:24:47.037411Z",
     "start_time": "2021-03-18T02:24:34.125430Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 47)]              0         \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  ((None, 47, 1024), (None, 334607360 \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 47, 300)           1410000   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 47, 50)            15050     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 47, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf (CRF)                    (None, 47, 4)             16        \n",
      "=================================================================\n",
      "Total params: 336,032,630\n",
      "Trainable params: 336,032,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T02:25:43.615656Z",
     "start_time": "2021-03-18T02:24:47.039416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Train on 216750 samples, validate on 38250 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "    64/216750 [..............................] - ETA: 52:18:38WARNING:tensorflow:Early stopping conditioned on metric `val_viterbi_accuracy` which is not available. Available metrics are: \n",
      "WARNING:tensorflow:Can save best model only with val_viterbi_accuracy available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_viterbi_accuracy` which is not available. Available metrics are: lr\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[64,47,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:64) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/viterbi_accuracy/mul/_1048]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[64,47,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:64) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_75176]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv:\n model/tf_bert_model/bert/encoder/layer_._2/intermediate/dense/BiasAdd (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:320)\n\nInput Source operations connected to node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv:\n model/tf_bert_model/bert/encoder/layer_._2/intermediate/dense/BiasAdd (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:320)\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-17f5f3cbbb69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce_lr_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[64,47,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:64) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/viterbi_accuracy/mul/_1048]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[64,47,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:64) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_75176]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv:\n model/tf_bert_model/bert/encoder/layer_._2/intermediate/dense/BiasAdd (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:320)\n\nInput Source operations connected to node model/tf_bert_model/bert/encoder/layer_._2/intermediate/activation/truediv:\n model/tf_bert_model/bert/encoder/layer_._2/intermediate/dense/BiasAdd (defined at C:\\Users\\BIGDATA02\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_tf_bert.py:320)\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_viterbi_accuracy', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('best_street.h5', save_best_only=True,save_weights_only=True, monitor='val_viterbi_accuracy', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_viterbi_accuracy', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(X_train, np.array(y_train), \n",
    "                    batch_size=64, \n",
    "                    epochs=50, \n",
    "                    validation_split=0.15,\n",
    "                    callbacks=[earlyStopping,mcp_save,reduce_lr_loss],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T15:06:23.905604Z",
     "start_time": "2021-03-15T15:06:23.887506Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_graphs(history, string):\n",
    "#     plt.plot(history.history[string])\n",
    "#     plt.plot(history.history['val_'+string])\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.ylabel(string)\n",
    "#     plt.legend([string, 'val_'+string])\n",
    "#     plt.show()\n",
    "  \n",
    "\n",
    "# plot_graphs(history, \"accuracy\")\n",
    "# plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:55:01.634862Z",
     "start_time": "2021-03-16T16:55:01.628841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x2342e9e2d90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:55:07.596531Z",
     "start_time": "2021-03-16T16:55:07.493129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred  GT             \n",
      "raya           : B-street B-street        \n",
      "banj           : I-street I-street        \n",
      "no             : O     O               \n",
      "496            : O     O               \n",
      "photo          : O     O               \n",
      "copy           : O     O               \n",
      "laris,         : O     O               \n",
      "suka           : O     O               \n",
      "sari           : O     O               \n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(X_test))\n",
    "# i = 42087\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5} {:15}\".format(\"Word\",  \"Pred\", 'GT'))\n",
    "for w, pred, gt in zip(X_test[i], p[0], list(np.argmax(y_test[i],axis=-1))):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} {:15} \".format(raw_tokenizer.index_word[w], idx2tag[pred], idx2tag[gt]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:56:56.523285Z",
     "start_time": "2021-03-16T16:56:56.510287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6602"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:04:49.228289Z",
     "start_time": "2021-03-16T17:04:49.094292Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('street_20200316.h5')\n",
    "model.save_weights('street_20200316.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:06:03.127091Z",
     "start_time": "2021-03-16T17:06:02.502255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5763, 175, 212, 12766, 13, 1316]]\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_10 (CRF)                 (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x235a33687f0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'wig ten iv, gununganyartambak kel. gununganyar'\n",
    "word_idx = [[word2idx[w] for w in s] for s in [word.split(' ')]]\n",
    "print(word_idx)\n",
    "model_street = build_model(raw_vocab_size,target_vocab_size,max_len)\n",
    "model_street.load_weights('street_20200316.h5')\n",
    "\n",
    "# model_street = tf.keras.models.load_model('street_20200316.h5',custom_objects={'CRF':CRF(n_tags)})\n",
    "model_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:58:38.748618Z",
     "start_time": "2021-03-16T16:58:38.733586Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:06:13.909946Z",
     "start_time": "2021-03-16T17:06:11.517674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred  GT             \n",
      "raya           : B-street B-street        \n",
      "banj           : I-street I-street        \n",
      "no             : O     O               \n",
      "496            : O     O               \n",
      "photo          : O     O               \n",
      "copy           : O     O               \n",
      "laris,         : O     O               \n",
      "suka           : O     O               \n",
      "sari           : O     O               \n"
     ]
    }
   ],
   "source": [
    "# i = random.randint(0,len(X_test))\n",
    "# i = 42087\n",
    "p = model_street.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5} {:15}\".format(\"Word\",  \"Pred\", 'GT'))\n",
    "for w, pred, gt in zip(X_test[i], p[0], list(np.argmax(y_test[i],axis=-1))):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} {:15} \".format(raw_tokenizer.index_word[w], idx2tag[pred], idx2tag[gt]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:09:48.387706Z",
     "start_time": "2021-03-16T17:09:48.374662Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model_street.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_test_true = np.argmax(y_test, -1)\n",
    "\n",
    "y_pred = [[idx2tag[i] for i in row] for row in y_pred]\n",
    "y_test_true = [[idx2tag[i] for i in row] for row in y_test_true] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:10:09.853169Z",
     "start_time": "2021-03-16T17:09:51.093601Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is : 91.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-street       0.81      0.83      0.82     29891\n",
      "    I-street       0.82      0.85      0.83     40820\n",
      "           O       0.95      0.95      0.95    236144\n",
      "         PAD       1.00      1.00      1.00   1133145\n",
      "\n",
      "    accuracy                           0.98   1440000\n",
      "   macro avg       0.90      0.91      0.90   1440000\n",
      "weighted avg       0.98      0.98      0.98   1440000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score is : {:.1%}\".format(f1_score(y_test_true, y_pred)))\n",
    "report = flat_classification_report(y_pred=y_pred, y_true=y_test_true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T15:10:38.828664Z",
     "start_time": "2021-03-17T15:10:38.823629Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
