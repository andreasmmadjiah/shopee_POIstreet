{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T14:22:00.112266Z",
     "start_time": "2021-03-16T14:21:59.064716Z"
    }
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:35.568492Z",
     "start_time": "2021-03-16T16:09:32.571737Z"
    },
    "id": "i5K8aIW1GKYP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:35.584458Z",
     "start_time": "2021-03-16T16:09:35.570484Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D, Input\n",
    "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:09:32.563662Z",
     "start_time": "2021-03-16T17:09:21.683953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in e:\\anaconda3\\envs\\andre\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: tabulate in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from sklearn-crfsuite) (0.8.7)\n",
      "Requirement already satisfied: six in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from sklearn-crfsuite) (1.15.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from sklearn-crfsuite) (4.47.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from sklearn-crfsuite) (0.9.7)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from seqeval) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from seqeval) (0.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in e:\\anaconda3\\envs\\andre\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16176 sha256=ffe58a1691d727828d8cbec67a9d7ac77fb97f3be6454ca908f013c739144ab0\n",
      "  Stored in directory: c:\\users\\andreas m\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite\n",
    "!pip install seqeval\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:13:55.211315Z",
     "start_time": "2021-03-16T16:13:55.183316Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow_addons.layers.crf import CRF\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras_contrib.layers import CRF\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from crf import CRF\n",
    "# !pip install tf2crf\n",
    "# from tf2CRF import CRF\n",
    "\n",
    "# from tf2crf import CRF, ModelWithCRFLoss\n",
    "# from keras_contrib.metrics import crf_accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "\n",
    "\n",
    "class CRF(L.Layer):\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 sparse_target=True,\n",
    "                 **kwargs):\n",
    "        \"\"\"    \n",
    "        Args:\n",
    "            output_dim (int): the number of labels to tag each temporal input.\n",
    "            sparse_target (bool): whether the the ground-truth label represented in one-hot.\n",
    "        Input shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        Output shape:\n",
    "            (batch_size, sentence length, output_dim)\n",
    "        \"\"\"\n",
    "        super(CRF, self).__init__(**kwargs)\n",
    "        self.output_dim = int(output_dim) \n",
    "        self.sparse_target = sparse_target\n",
    "        self.input_spec = L.InputSpec(min_ndim=3)\n",
    "        self.supports_masking = False\n",
    "        self.sequence_lengths = None\n",
    "        self.transitions = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        f_shape = tf.TensorShape(input_shape)\n",
    "        input_spec = L.InputSpec(min_ndim=3, axes={-1: f_shape[-1]})\n",
    "\n",
    "        if f_shape[-1] is None:\n",
    "            raise ValueError('The last dimension of the inputs to `CRF` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        if f_shape[-1] != self.output_dim:\n",
    "            raise ValueError('The last dimension of the input shape must be equal to output'\n",
    "                             ' shape. Use a linear layer if needed.')\n",
    "        self.input_spec = input_spec\n",
    "        self.transitions = self.add_weight(name='transitions',\n",
    "                                           shape=[self.output_dim, self.output_dim],\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Just pass the received mask from previous layer, to the next layer or\n",
    "        # manipulate it if this layer changes the shape of the input\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs, sequence_lengths=None, training=None, **kwargs):\n",
    "        sequences = tf.convert_to_tensor(inputs, dtype=self.dtype)\n",
    "        if sequence_lengths is not None:\n",
    "            assert len(sequence_lengths.shape) == 2\n",
    "            assert tf.convert_to_tensor(sequence_lengths).dtype == 'int32'\n",
    "            seq_len_shape = tf.convert_to_tensor(sequence_lengths).get_shape().as_list()\n",
    "            assert seq_len_shape[1] == 1\n",
    "            self.sequence_lengths = K.flatten(sequence_lengths)\n",
    "        else:\n",
    "            self.sequence_lengths = tf.ones(tf.shape(inputs)[0], dtype=tf.int32) * (\n",
    "                tf.shape(inputs)[1]\n",
    "            )\n",
    "\n",
    "        viterbi_sequence, _ = crf_decode(sequences,\n",
    "                                         self.transitions,\n",
    "                                         self.sequence_lengths)\n",
    "        output = K.one_hot(viterbi_sequence, self.output_dim)\n",
    "        return K.in_train_phase(sequences, output)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        def crf_loss(y_true, y_pred):\n",
    "            y_pred = tf.convert_to_tensor(y_pred, dtype=self.dtype)\n",
    "            log_likelihood, self.transitions = crf_log_likelihood(\n",
    "                y_pred,\n",
    "                tf.cast(K.argmax(y_true), dtype=tf.int32) if self.sparse_target else y_true,\n",
    "                self.sequence_lengths,\n",
    "                transition_params=self.transitions,\n",
    "            )\n",
    "            return tf.reduce_mean(-log_likelihood)\n",
    "        return crf_loss\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        def viterbi_accuracy(y_true, y_pred):\n",
    "            # -1e10 to avoid zero at sum(mask)\n",
    "            mask = K.cast(\n",
    "                K.all(K.greater(y_pred, -1e10), axis=2), K.floatx())\n",
    "            shape = tf.shape(y_pred)\n",
    "            sequence_lengths = tf.ones(shape[0], dtype=tf.int32) * (shape[1])\n",
    "            y_pred, _ = crf_decode(y_pred, self.transitions, sequence_lengths)\n",
    "            if self.sparse_target:\n",
    "                y_true = K.argmax(y_true, 2)\n",
    "            y_pred = K.cast(y_pred, 'int32')\n",
    "            y_true = K.cast(y_true, 'int32')\n",
    "            corrects = K.cast(K.equal(y_true, y_pred), K.floatx())\n",
    "            return K.sum(corrects * mask) / K.sum(mask)\n",
    "        return viterbi_accuracy\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        tf.TensorShape(input_shape).assert_has_rank(3)\n",
    "        return input_shape[:2] + (self.output_dim,)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'sparse_target': self.sparse_target,\n",
    "            'supports_masking': self.supports_masking,\n",
    "            'transitions': K.eval(self.transitions)\n",
    "        }\n",
    "        base_config = super(CRF, self).get_config()\n",
    "        return dict(base_config, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:06:59.355912Z",
     "start_time": "2021-03-16T16:06:59.227872Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:35.724489Z",
     "start_time": "2021-03-16T16:09:35.710459Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:36.139825Z",
     "start_time": "2021-03-16T16:09:35.726458Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "0814LcuSGVDC",
    "outputId": "bcf6f3ca-7a4f-499f-c120-d0561aed845a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>/jl kapuk timur delta sili iii lippo cika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>/siung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>toko dita/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>/jl. orde baru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        raw_address  \\\n",
       "0   0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1   1                                 aye, jati sampurna   \n",
       "2   2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3   3                               toko dita, kertosono   \n",
       "4   4                                      jl. orde baru   \n",
       "\n",
       "                                  POI/street  \n",
       "0  /jl kapuk timur delta sili iii lippo cika  \n",
       "1                                          /  \n",
       "2                                     /siung  \n",
       "3                                 toko dita/  \n",
       "4                             /jl. orde baru  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:36.187828Z",
     "start_time": "2021-03-16T16:09:36.141828Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "ic-_6IAFGi_F",
    "outputId": "d3eaf4ed-8b52-41d5-8245-b871a7421934"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    raw_address\n",
       "0   0          s. par 53 sidanegara 4 cilacap tengah\n",
       "1   1          angg per, baloi indah kel. lubuk baja\n",
       "2   2                          asma laun, mand imog,\n",
       "3   3  ud agung rej, raya nga sri wedari karanganyar\n",
       "4   4                     cut mutia, 35 baiturrahman"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:37.014933Z",
     "start_time": "2021-03-16T16:09:36.191835Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "vUkhehRxGjNK",
    "outputId": "7751a984-3947-4306-bd61-0e20849a701b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>street</th>\n",
       "      <th>raw_split</th>\n",
       "      <th>street_split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika</td>\n",
       "      <td>['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...</td>\n",
       "      <td>['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...</td>\n",
       "      <td>['B-street', 'I-street', 'I-street', 'I-street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['aye,', 'jati', 'sampurna']</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>siung</td>\n",
       "      <td>['setu', 'siung', '119', 'rt', '5', '1', '1388...</td>\n",
       "      <td>['siung']</td>\n",
       "      <td>['O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['toko', 'dita,', 'kertosono']</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>['jl.', 'orde', 'baru']</td>\n",
       "      <td>['jl.', 'orde', 'baru']</td>\n",
       "      <td>['B-street', 'I-street', 'I-street']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1                                 aye, jati sampurna   \n",
       "2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3                               toko dita, kertosono   \n",
       "4                                      jl. orde baru   \n",
       "\n",
       "                                     street  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika   \n",
       "1                                       NaN   \n",
       "2                                     siung   \n",
       "3                                       NaN   \n",
       "4                             jl. orde baru   \n",
       "\n",
       "                                           raw_split  \\\n",
       "0  ['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...   \n",
       "1                       ['aye,', 'jati', 'sampurna']   \n",
       "2  ['setu', 'siung', '119', 'rt', '5', '1', '1388...   \n",
       "3                     ['toko', 'dita,', 'kertosono']   \n",
       "4                            ['jl.', 'orde', 'baru']   \n",
       "\n",
       "                                        street_split  \\\n",
       "0  ['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...   \n",
       "1                                               ['']   \n",
       "2                                          ['siung']   \n",
       "3                                               ['']   \n",
       "4                            ['jl.', 'orde', 'baru']   \n",
       "\n",
       "                                               label  \n",
       "0  ['B-street', 'I-street', 'I-street', 'I-street...  \n",
       "1                                    ['O', 'O', 'O']  \n",
       "2    ['O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O']  \n",
       "3                                    ['O', 'O', 'O']  \n",
       "4               ['B-street', 'I-street', 'I-street']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_label = pd.read_csv('data_train_label.csv')\n",
    "data_train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:42.444657Z",
     "start_time": "2021-03-16T16:09:37.017936Z"
    },
    "id": "p9U85hTqIezb"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "list_y = data_train_label['label'].apply(lambda x: ast.literal_eval(x)).values\n",
    "\n",
    "data_train_label['raw_split'] = data_train_label['raw'].apply(lambda x: [x1 for x1 in x.split(' ') if x1!='']).values\n",
    "list_x = data_train_label['raw_split'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:42.460653Z",
     "start_time": "2021-03-16T16:09:42.446662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['B-street', 'I-street', 'I-street', 'I-street', 'I-street', 'I-street', 'I-street', 'I-street', 'O', 'O', 'O', 'O', 'O'])\n",
      " list(['O', 'O', 'O'])\n",
      " list(['O', 'B-street', 'O', 'O', 'O', 'O', 'O', 'O'])\n",
      " list(['O', 'O', 'O'])]\n"
     ]
    }
   ],
   "source": [
    "print(list_y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:42.475654Z",
     "start_time": "2021-03-16T16:09:42.462655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii', 'lippo', 'cika', '11', 'a', 'cicau', 'cikarang', 'pusat'])\n",
      " list(['aye,', 'jati', 'sampurna'])\n",
      " list(['setu', 'siung', '119', 'rt', '5', '1', '13880', 'cipayung'])\n",
      " list(['toko', 'dita,', 'kertosono'])]\n"
     ]
    }
   ],
   "source": [
    "print(list_x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:42.568686Z",
     "start_time": "2021-03-16T16:09:42.477653Z"
    },
    "id": "ySR7hricKkbA"
   },
   "outputs": [],
   "source": [
    "data_train_label['label_join'] = [' '.join(x) for x in list_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:42.584685Z",
     "start_time": "2021-03-16T16:09:42.570655Z"
    },
    "id": "Aaf1Ai7NKRju"
   },
   "outputs": [],
   "source": [
    "raw_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')  # the filters ='' so that keras doesnot remove any punctuation in our data\n",
    "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:42.600223Z",
     "start_time": "2021-03-16T16:09:42.587152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:46.809684Z",
     "start_time": "2021-03-16T16:09:42.602030Z"
    },
    "id": "FPqjWWAxKTJt"
   },
   "outputs": [],
   "source": [
    "# raw data train and test concat so that there is no word that does not have index\n",
    "raw_data = pd.concat([train['raw_address'],test['raw_address']],axis=0).values\n",
    "target_data = data_train_label['label_join'].values\n",
    "\n",
    "\n",
    "raw_tokenizer.fit_on_texts(raw_data)\n",
    "target_tokenizer.fit_on_texts(target_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:46.825586Z",
     "start_time": "2021-03-16T16:09:46.811585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saya', '', 'mau', 'makan']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[5944, 11461, 269]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'saya  mau makan'\n",
    "print(a.split(' '))\n",
    "raw_tokenizer.texts_to_sequences([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:46.841227Z",
     "start_time": "2021-03-16T16:09:46.827586Z"
    }
   },
   "outputs": [],
   "source": [
    "tag2idx = {}\n",
    "for key in target_tokenizer.word_index.keys():\n",
    "    tag2idx[key] = target_tokenizer.word_index[key]\n",
    "\n",
    "idx2tag = {}\n",
    "for key in target_tokenizer.index_word.keys():\n",
    "    idx2tag[key] = target_tokenizer.index_word[key]\n",
    "idx2tag\n",
    "\n",
    "tag2idx['PAD'] = 0\n",
    "idx2tag[0]='PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:46.920716Z",
     "start_time": "2021-03-16T16:09:46.842122Z"
    }
   },
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "for key in raw_tokenizer.word_index.keys():\n",
    "    word2idx[key] = raw_tokenizer.word_index[key]\n",
    "\n",
    "idx2word = {}\n",
    "for key in raw_tokenizer.index_word.keys():\n",
    "    idx2word[key] = raw_tokenizer.index_word[key]\n",
    "idx2word\n",
    "\n",
    "word2idx['PAD'] = 0\n",
    "idx2word[0]='PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:50.252157Z",
     "start_time": "2021-03-16T16:09:46.921702Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkluEJPcLBxz",
    "outputId": "f95df97b-6703-452a-9abb-41fe4ab1cf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   59   275    10   886 11880    48  2171   774    31    60  8116   104\n",
      "    309     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [20376    47   476     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [  415 22368  1529     2    11     4 10063   165     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n",
      "[[3 2 2 2 2 2 2 2 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# X = raw_tokenizer.texts_to_sequences(train['raw_address'])\n",
    "X = [[word2idx[w] for w in s] for s in list_x]\n",
    "data_target_in = [[tag2idx[w] for w in s] for s in list_y]\n",
    "\n",
    "# Add 0 padding so all data has the same length\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X,padding='post',value=word2idx['PAD'])\n",
    "print(X[:3])\n",
    "\n",
    "data_target_in = tf.keras.preprocessing.sequence.pad_sequences(data_target_in,padding='post',value=tag2idx['PAD'])\n",
    "print(data_target_in[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:50.268039Z",
     "start_time": "2021-03-16T16:09:50.254043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jl',\n",
       " 'kapuk',\n",
       " 'timur',\n",
       " 'delta',\n",
       " 'sili',\n",
       " 'iii',\n",
       " 'lippo',\n",
       " 'cika',\n",
       " '11',\n",
       " 'a',\n",
       " 'cicau',\n",
       " 'cikarang',\n",
       " 'pusat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2word[x] for x in X[0] if x!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:52.933462Z",
     "start_time": "2021-03-16T16:09:50.270041Z"
    },
    "id": "JcWFMOYeLxCa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tag2idx)\n",
    "# n_tags\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in data_target_in]\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:53.552669Z",
     "start_time": "2021-03-16T16:09:52.935484Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:53.568668Z",
     "start_time": "2021-03-16T16:09:53.554644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255000, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:53.584676Z",
     "start_time": "2021-03-16T16:09:53.571644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:53.600674Z",
     "start_time": "2021-03-16T16:09:53.585670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:53.616674Z",
     "start_time": "2021-03-16T16:09:53.601654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:09:53.632674Z",
     "start_time": "2021-03-16T16:09:53.617669Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_vocab_size = len(raw_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(idx2tag)\n",
    "\n",
    "max_len = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:52:27.277054Z",
     "start_time": "2021-03-16T16:52:27.270053Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(raw_vocab_size,target_vocab_size,max_len):\n",
    "    input_ = Input(shape=(max_len,))\n",
    "    model = Embedding(input_dim=raw_vocab_size, output_dim=50, input_length=max_len, mask_zero = True)(input_)\n",
    "    model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "    model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
    "    model = Dense(n_tags)(model)\n",
    "    crf = CRF(n_tags)\n",
    "    out = crf(model)\n",
    "    model = Model(input_, out)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "    # model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])          \n",
    "    model.compile(optimizer=\"rmsprop\", loss= crf.loss, metrics=[crf.accuracy])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:14:54.029139Z",
     "start_time": "2021-03-16T16:14:53.333883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_3 (CRF)                  (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=raw_vocab_size, output_dim=50, input_length=max_len, mask_zero = True)(input_)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
    "model = Dense(n_tags)(model)\n",
    "crf = CRF(n_tags)\n",
    "out = crf(model)\n",
    "model = Model(input_, out)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "# model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])          \n",
    "model.compile(optimizer=\"rmsprop\", loss= crf.loss, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:47:45.173359Z",
     "start_time": "2021-03-16T16:14:57.205027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/20\n",
      "424/424 [==============================] - 165s 388ms/step - loss: 3.3588 - viterbi_accuracy: 0.8739 - val_loss: 16.8015 - val_viterbi_accuracy: 0.9793\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 161s 381ms/step - loss: 0.2592 - viterbi_accuracy: 0.9831 - val_loss: 9.9422 - val_viterbi_accuracy: 0.9821\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 162s 381ms/step - loss: 0.1878 - viterbi_accuracy: 0.9857 - val_loss: 6.7916 - val_viterbi_accuracy: 0.9835\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 161s 380ms/step - loss: 0.1504 - viterbi_accuracy: 0.9873 - val_loss: 4.9709 - val_viterbi_accuracy: 0.9838\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 162s 383ms/step - loss: 0.1274 - viterbi_accuracy: 0.9886 - val_loss: 4.1083 - val_viterbi_accuracy: 0.9817\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 161s 380ms/step - loss: 0.1120 - viterbi_accuracy: 0.9895 - val_loss: 3.5166 - val_viterbi_accuracy: 0.9823\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 160s 378ms/step - loss: 0.1011 - viterbi_accuracy: 0.9903 - val_loss: 3.2742 - val_viterbi_accuracy: 0.9812\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 161s 379ms/step - loss: 0.0925 - viterbi_accuracy: 0.9911 - val_loss: 3.0863 - val_viterbi_accuracy: 0.9814\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 161s 379ms/step - loss: 0.0854 - viterbi_accuracy: 0.9917 - val_loss: 3.0268 - val_viterbi_accuracy: 0.9811\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 161s 379ms/step - loss: 0.0794 - viterbi_accuracy: 0.9923 - val_loss: 2.9751 - val_viterbi_accuracy: 0.9807\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 161s 380ms/step - loss: 0.0746 - viterbi_accuracy: 0.9927 - val_loss: 3.0305 - val_viterbi_accuracy: 0.9795\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 162s 381ms/step - loss: 0.0701 - viterbi_accuracy: 0.9931 - val_loss: 3.0110 - val_viterbi_accuracy: 0.9799\n",
      "Epoch 13/20\n",
      " 39/424 [=>............................] - ETA: 2:18 - loss: 0.0609 - viterbi_accuracy: 0.9940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d5f1280d3e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history = model.fit(X_train, np.array(y_train), \n\u001b[0m\u001b[0;32m      7\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('best.h5', save_best_only=True,save_weights_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(X_train, np.array(y_train), \n",
    "                    batch_size=512, \n",
    "                    epochs=20, \n",
    "                    validation_split=0.15,\n",
    "                    callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T15:06:23.905604Z",
     "start_time": "2021-03-15T15:06:23.887506Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_graphs(history, string):\n",
    "#     plt.plot(history.history[string])\n",
    "#     plt.plot(history.history['val_'+string])\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.ylabel(string)\n",
    "#     plt.legend([string, 'val_'+string])\n",
    "#     plt.show()\n",
    "  \n",
    "\n",
    "# plot_graphs(history, \"accuracy\")\n",
    "# plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:55:01.634862Z",
     "start_time": "2021-03-16T16:55:01.628841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x2342e9e2d90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:55:07.596531Z",
     "start_time": "2021-03-16T16:55:07.493129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred  GT             \n",
      "raya           : B-street B-street        \n",
      "banj           : I-street I-street        \n",
      "no             : O     O               \n",
      "496            : O     O               \n",
      "photo          : O     O               \n",
      "copy           : O     O               \n",
      "laris,         : O     O               \n",
      "suka           : O     O               \n",
      "sari           : O     O               \n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(X_test))\n",
    "# i = 42087\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5} {:15}\".format(\"Word\",  \"Pred\", 'GT'))\n",
    "for w, pred, gt in zip(X_test[i], p[0], list(np.argmax(y_test[i],axis=-1))):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} {:15} \".format(raw_tokenizer.index_word[w], idx2tag[pred], idx2tag[gt]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:56:56.523285Z",
     "start_time": "2021-03-16T16:56:56.510287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6602"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:04:49.228289Z",
     "start_time": "2021-03-16T17:04:49.094292Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('street_20200316.h5')\n",
    "model.save_weights('street_20200316.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:06:03.127091Z",
     "start_time": "2021-03-16T17:06:02.502255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5763, 175, 212, 12766, 13, 1316]]\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_10 (CRF)                 (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x235a33687f0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'wig ten iv, gununganyartambak kel. gununganyar'\n",
    "word_idx = [[word2idx[w] for w in s] for s in [word.split(' ')]]\n",
    "print(word_idx)\n",
    "model_street = build_model(raw_vocab_size,target_vocab_size,max_len)\n",
    "model_street.load_weights('street_20200316.h5')\n",
    "\n",
    "# model_street = tf.keras.models.load_model('street_20200316.h5',custom_objects={'CRF':CRF(n_tags)})\n",
    "model_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T16:58:38.748618Z",
     "start_time": "2021-03-16T16:58:38.733586Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:06:13.909946Z",
     "start_time": "2021-03-16T17:06:11.517674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred  GT             \n",
      "raya           : B-street B-street        \n",
      "banj           : I-street I-street        \n",
      "no             : O     O               \n",
      "496            : O     O               \n",
      "photo          : O     O               \n",
      "copy           : O     O               \n",
      "laris,         : O     O               \n",
      "suka           : O     O               \n",
      "sari           : O     O               \n"
     ]
    }
   ],
   "source": [
    "# i = random.randint(0,len(X_test))\n",
    "# i = 42087\n",
    "p = model_street.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5} {:15}\".format(\"Word\",  \"Pred\", 'GT'))\n",
    "for w, pred, gt in zip(X_test[i], p[0], list(np.argmax(y_test[i],axis=-1))):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} {:15} \".format(raw_tokenizer.index_word[w], idx2tag[pred], idx2tag[gt]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:09:48.387706Z",
     "start_time": "2021-03-16T17:09:48.374662Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model_street.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_test_true = np.argmax(y_test, -1)\n",
    "\n",
    "y_pred = [[idx2tag[i] for i in row] for row in y_pred]\n",
    "y_test_true = [[idx2tag[i] for i in row] for row in y_test_true] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:10:09.853169Z",
     "start_time": "2021-03-16T17:09:51.093601Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is : 91.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-street       0.81      0.83      0.82     29891\n",
      "    I-street       0.82      0.85      0.83     40820\n",
      "           O       0.95      0.95      0.95    236144\n",
      "         PAD       1.00      1.00      1.00   1133145\n",
      "\n",
      "    accuracy                           0.98   1440000\n",
      "   macro avg       0.90      0.91      0.90   1440000\n",
      "weighted avg       0.98      0.98      0.98   1440000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score is : {:.1%}\".format(f1_score(y_test_true, y_pred)))\n",
    "report = flat_classification_report(y_pred=y_pred, y_true=y_test_true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:17.183659Z",
     "start_time": "2021-03-16T18:03:16.449586Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "vUkhehRxGjNK",
    "outputId": "7751a984-3947-4306-bd61-0e20849a701b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>poi</th>\n",
       "      <th>raw_split</th>\n",
       "      <th>poi_split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['aye,', 'jati', 'sampurna']</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['setu', 'siung', '119', 'rt', '5', '1', '1388...</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>toko dita</td>\n",
       "      <td>['toko', 'dita,', 'kertosono']</td>\n",
       "      <td>['toko', 'dita']</td>\n",
       "      <td>['B-poi', 'I-poi', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['jl.', 'orde', 'baru']</td>\n",
       "      <td>['']</td>\n",
       "      <td>['O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw        poi  \\\n",
       "0  jl kapuk timur delta sili iii lippo cika 11 a ...        NaN   \n",
       "1                                 aye, jati sampurna        NaN   \n",
       "2               setu siung 119 rt 5 1 13880 cipayung        NaN   \n",
       "3                               toko dita, kertosono  toko dita   \n",
       "4                                      jl. orde baru        NaN   \n",
       "\n",
       "                                           raw_split         poi_split  \\\n",
       "0  ['jl', 'kapuk', 'timur', 'delta', 'sili', 'iii...              ['']   \n",
       "1                       ['aye,', 'jati', 'sampurna']              ['']   \n",
       "2  ['setu', 'siung', '119', 'rt', '5', '1', '1388...              ['']   \n",
       "3                     ['toko', 'dita,', 'kertosono']  ['toko', 'dita']   \n",
       "4                            ['jl.', 'orde', 'baru']              ['']   \n",
       "\n",
       "                                               label  \n",
       "0  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "1                                    ['O', 'O', 'O']  \n",
       "2           ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']  \n",
       "3                            ['B-poi', 'I-poi', 'O']  \n",
       "4                                    ['O', 'O', 'O']  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_label = pd.read_csv('data_train_label_poi.csv')\n",
    "data_train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:24.914927Z",
     "start_time": "2021-03-16T18:03:17.185667Z"
    },
    "id": "p9U85hTqIezb"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "list_y = data_train_label['label'].apply(lambda x: ast.literal_eval(x)).values\n",
    "\n",
    "data_train_label['raw_split'] = data_train_label['raw'].apply(lambda x: [x1 for x1 in x.split(' ') if x1!='']).values\n",
    "list_x = data_train_label['raw_split'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:24.930945Z",
     "start_time": "2021-03-16T18:03:24.916929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n",
      " list(['O', 'O', 'O']) list(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n",
      " list(['B-poi', 'I-poi', 'O'])]\n"
     ]
    }
   ],
   "source": [
    "print(list_y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:25.010939Z",
     "start_time": "2021-03-16T18:03:24.932929Z"
    },
    "id": "ySR7hricKkbA"
   },
   "outputs": [],
   "source": [
    "data_train_label['label_join'] = [' '.join(x) for x in list_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:25.026930Z",
     "start_time": "2021-03-16T18:03:25.012932Z"
    },
    "id": "Aaf1Ai7NKRju"
   },
   "outputs": [],
   "source": [
    "# raw_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')  # the filters ='' so that keras doesnot remove any punctuation in our data\n",
    "target_tokenizer2 = tf.keras.preprocessing.text.Tokenizer(filters='',lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:26.284248Z",
     "start_time": "2021-03-16T18:03:25.028931Z"
    },
    "id": "FPqjWWAxKTJt"
   },
   "outputs": [],
   "source": [
    "# raw data train and test concat so that there is no word that does not have index\n",
    "# raw_data = pd.concat([train['raw_address'],test['raw_address']],axis=0).values\n",
    "target_data = data_train_label['label_join'].values\n",
    "\n",
    "\n",
    "# raw_tokenizer.fit_on_texts(raw_data)\n",
    "target_tokenizer2.fit_on_texts(target_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:26.299250Z",
     "start_time": "2021-03-16T18:03:26.285250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 1, 'I-poi': 2, 'B-poi': 3}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokenizer2.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:26.314250Z",
     "start_time": "2021-03-16T18:03:26.302252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'O', 2: 'I-poi', 3: 'B-poi', 0: 'PAD'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx2 = {}\n",
    "for key in target_tokenizer2.word_index.keys():\n",
    "    tag2idx2[key] = target_tokenizer2.word_index[key]\n",
    "\n",
    "idx2tag2 = {}\n",
    "for key in target_tokenizer2.index_word.keys():\n",
    "    idx2tag2[key] = target_tokenizer2.index_word[key]\n",
    "idx2tag2\n",
    "\n",
    "tag2idx2['PAD'] = 0\n",
    "idx2tag2[0]='PAD'\n",
    "idx2tag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:27.650916Z",
     "start_time": "2021-03-16T18:03:26.318251Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkluEJPcLBxz",
    "outputId": "f95df97b-6703-452a-9abb-41fe4ab1cf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 3 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# X = raw_tokenizer.texts_to_sequences(train['raw_address'])\n",
    "# X = [[word2idx[w] for w in s] for s in list_x]\n",
    "data_target_in = [[tag2idx2[w] for w in s] for s in list_y]\n",
    "\n",
    "# Add 0 padding so all data has the same length\n",
    "# X = tf.keras.preprocessing.sequence.pad_sequences(X,padding='post',value=word2idx['PAD'])\n",
    "# print(X[:3])\n",
    "\n",
    "data_target_in = tf.keras.preprocessing.sequence.pad_sequences(data_target_in,padding='post',value=tag2idx2['PAD'])\n",
    "print(data_target_in[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:30.691632Z",
     "start_time": "2021-03-16T18:03:27.651881Z"
    },
    "id": "JcWFMOYeLxCa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tag2idx2)\n",
    "# n_tags\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in data_target_in]\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:32.001952Z",
     "start_time": "2021-03-16T18:03:30.693633Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:32.017953Z",
     "start_time": "2021-03-16T18:03:32.003953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255000, 32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:32.033951Z",
     "start_time": "2021-03-16T18:03:32.019953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:32.048952Z",
     "start_time": "2021-03-16T18:03:32.035953Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_vocab_size = len(raw_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(idx2tag)\n",
    "\n",
    "max_len = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:03:32.699258Z",
     "start_time": "2021-03-16T18:03:32.051744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_16 (Embedding)     (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_17 (CRF)                 (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(raw_vocab_size,target_vocab_size,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:33:08.332756Z",
     "start_time": "2021-03-16T18:03:32.701226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/20\n",
      "424/424 [==============================] - 171s 403ms/step - loss: 3.3004 - viterbi_accuracy: 0.8554 - val_loss: 16.3783 - val_viterbi_accuracy: 0.9797\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 169s 399ms/step - loss: 0.2449 - viterbi_accuracy: 0.9848 - val_loss: 9.4246 - val_viterbi_accuracy: 0.9848\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 168s 396ms/step - loss: 0.1645 - viterbi_accuracy: 0.9875 - val_loss: 6.2216 - val_viterbi_accuracy: 0.9862\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 172s 405ms/step - loss: 0.1221 - viterbi_accuracy: 0.9894 - val_loss: 4.5954 - val_viterbi_accuracy: 0.9861\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 170s 400ms/step - loss: 0.0962 - viterbi_accuracy: 0.9910 - val_loss: 3.4824 - val_viterbi_accuracy: 0.9870\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 172s 406ms/step - loss: 0.0788 - viterbi_accuracy: 0.9923 - val_loss: 2.9497 - val_viterbi_accuracy: 0.9836\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 171s 404ms/step - loss: 0.0667 - viterbi_accuracy: 0.9934 - val_loss: 2.6589 - val_viterbi_accuracy: 0.9830\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 168s 396ms/step - loss: 0.0573 - viterbi_accuracy: 0.9942 - val_loss: 2.5044 - val_viterbi_accuracy: 0.9830\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 165s 389ms/step - loss: 0.0500 - viterbi_accuracy: 0.9950 - val_loss: 2.3761 - val_viterbi_accuracy: 0.9830\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 160s 377ms/step - loss: 0.0440 - viterbi_accuracy: 0.9956 - val_loss: 2.3273 - val_viterbi_accuracy: 0.9831\n",
      "Epoch 11/20\n",
      "205/424 [=============>................] - ETA: 1:19 - loss: 0.0378 - viterbi_accuracy: 0.9963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-70e071a84be2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history2 = model2.fit(X_train, np.array(y_train), \n\u001b[0m\u001b[0;32m      7\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\andre\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('best_poi.h5', save_best_only=True,save_weights_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "\n",
    "history2 = model2.fit(X_train, np.array(y_train), \n",
    "                    batch_size=512, \n",
    "                    epochs=20, \n",
    "                    validation_split=0.15,\n",
    "                    callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T15:06:23.905604Z",
     "start_time": "2021-03-15T15:06:23.887506Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:42:52.244977Z",
     "start_time": "2021-03-16T18:42:52.240975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36684"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:52:53.097358Z",
     "start_time": "2021-03-16T18:52:52.992363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred  GT             \n",
      "amb,           : O     O               \n",
      "toko           : B-poi B-poi           \n",
      "kelontong,     : I-poi I-poi           \n",
      "wuluhan        : O     O               \n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(X_test))\n",
    "# i = 42087\n",
    "p = model2.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5} {:15}\".format(\"Word\",  \"Pred\", 'GT'))\n",
    "for w, pred, gt in zip(X_test[i], p[0], list(np.argmax(y_test[i],axis=-1))):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} {:15} \".format(raw_tokenizer.index_word[w], idx2tag2[pred], idx2tag2[gt]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:33:13.459531Z",
     "start_time": "2021-03-16T18:33:13.356503Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('poi_20200316_last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:42:34.230851Z",
     "start_time": "2021-03-16T18:42:33.561607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5763, 175, 212, 12766, 13, 1316]]\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_23 (Embedding)     (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_24 (CRF)                 (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x2362c159cd0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 's. par 53 sidanegara 4 cilacap tengah'\n",
    "word_idx = [[word2idx[w] for w in s] for s in [word.split(' ')]]\n",
    "print(word_idx)\n",
    "model_poi = build_model(raw_vocab_size,target_vocab_size,max_len)\n",
    "# model_poi.load_weights('poi_20200316.h5')\n",
    "model_poi.load_weights('best_poi.h5')\n",
    "\n",
    "# model_street = tf.keras.models.load_model('street_20200316.h5',custom_objects={'CRF':CRF(n_tags)})\n",
    "model_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:43:45.592101Z",
     "start_time": "2021-03-16T18:43:45.488967Z"
    }
   },
   "outputs": [],
   "source": [
    "model_poi.save_weights('poi_20200316.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:55:49.376443Z",
     "start_time": "2021-03-16T18:55:47.106112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 32) for input Tensor(\"input_26:0\", shape=(None, 32), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
      "Word            Pred \n",
      "amb,           : O     \n",
      "toko           : O     \n",
      "kelontong,     : O     \n",
      "wuluhan        : O     \n"
     ]
    }
   ],
   "source": [
    "# i = random.randint(0,len(X_test))\n",
    "# i = 42087\n",
    "# p = model_poi.predict(np.array([X_test[i]]))\n",
    "# p = model_street.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5} {:15}\".format(\"Word\",  \"Pred\", 'GT'))\n",
    "for w, pred, gt in zip(X_test[i], p[0], list(np.argmax(y_test[i],axis=-1))):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} {:15} \".format(raw_tokenizer.index_word[w], idx2tag2[pred], idx2tag2[gt]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:01:19.160859Z",
     "start_time": "2021-03-16T19:01:19.105889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Pred \n",
      "s.             : B-poi \n",
      "par            : I-poi \n",
      "53             : O     \n",
      "sidanegara     : O     \n",
      "4              : O     \n",
      "cilacap        : O     \n",
      "tengah         : O     \n"
     ]
    }
   ],
   "source": [
    "# i = random.randint(0,len(X_test))\n",
    "word = 's. par 53 sidanegara 4 cilacap tengah'\n",
    "word_idx = [[word2idx[w] for w in s] for s in [word.split(' ')]]\n",
    "# p = model_poi.predict(np.array(word_idx))\n",
    "p = model_street.predict(np.array(word_idx))\n",
    "\n",
    "# i = 42087\n",
    "# p = model_poi.predict(np.array([X_test[i]]))\n",
    "# p = model_street.predict(np.array([X_test[i]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "\n",
    "print(\"{:15} {:5}\".format(\"Word\",  \"Pred\"))\n",
    "for w, pred in zip(word_idx[0], p[0]):\n",
    "    if w==0:\n",
    "        continue\n",
    "    print(\"{:15}: {:5} \".format(raw_tokenizer.index_word[w], idx2tag2[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:01:24.376953Z",
     "start_time": "2021-03-16T19:01:24.368955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:34:47.179428Z",
     "start_time": "2021-03-16T18:33:53.049590Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model_poi.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_test_true = np.argmax(y_test, -1)\n",
    "\n",
    "y_pred = [[idx2tag2[i] for i in row] for row in y_pred]\n",
    "y_test_true = [[idx2tag2[i] for i in row] for row in y_test_true] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:35:05.148263Z",
     "start_time": "2021-03-16T18:34:47.181403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is : 91.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-poi       0.76      0.76      0.76     13880\n",
      "       I-poi       0.75      0.78      0.76     25938\n",
      "           O       0.97      0.96      0.97    267037\n",
      "         PAD       1.00      1.00      1.00   1133145\n",
      "\n",
      "    accuracy                           0.99   1440000\n",
      "   macro avg       0.87      0.88      0.87   1440000\n",
      "weighted avg       0.99      0.99      0.99   1440000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score is : {:.1%}\".format(f1_score(y_test_true, y_pred)))\n",
    "report = flat_classification_report(y_pred=y_pred, y_true=y_test_true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:57:39.898924Z",
     "start_time": "2021-03-16T18:57:39.889929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[440, 394, 399, 3495, 8, 695, 43]]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:58:49.528977Z",
     "start_time": "2021-03-16T18:58:49.506007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>raw_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "      <td>[s., par, 53, sidanegara, 4, cilacap, tengah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "      <td>[angg, per,, baloi, indah, kel., lubuk, baja]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "      <td>[asma, laun,, mand, imog,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "      <td>[ud, agung, rej,, raya, nga, sri, wedari, kara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "      <td>[cut, mutia,, 35, baiturrahman]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    raw_address  \\\n",
       "0   0          s. par 53 sidanegara 4 cilacap tengah   \n",
       "1   1          angg per, baloi indah kel. lubuk baja   \n",
       "2   2                          asma laun, mand imog,   \n",
       "3   3  ud agung rej, raya nga sri wedari karanganyar   \n",
       "4   4                     cut mutia, 35 baiturrahman   \n",
       "\n",
       "                                           raw_split  \n",
       "0      [s., par, 53, sidanegara, 4, cilacap, tengah]  \n",
       "1      [angg, per,, baloi, indah, kel., lubuk, baja]  \n",
       "2                         [asma, laun,, mand, imog,]  \n",
       "3  [ud, agung, rej,, raya, nga, sri, wedari, kara...  \n",
       "4                    [cut, mutia,, 35, baiturrahman]  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:54:43.617362Z",
     "start_time": "2021-03-16T17:54:43.608369Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_vocab_size = len(raw_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(idx2tag)\n",
    "\n",
    "max_len = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T15:59:27.482966Z",
     "start_time": "2021-03-15T15:59:27.465968Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model(raw_vocab_size,target_vocab_size,max_len):\n",
    "#     input_ = Input(shape=(max_len,))\n",
    "#     model = Embedding(input_dim=raw_vocab_size, output_dim=50, input_length=max_len)(input_)\n",
    "#     model = Dropout(0.5)(model)\n",
    "#     model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "#     out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  \n",
    "#     model = Model(input_, out)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:43:55.669469Z",
     "start_time": "2021-03-16T18:43:54.537470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_24 (Embedding)     (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_25 (CRF)                 (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_25 (Embedding)     (None, 32, 50)            6612200   \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 32, 200)           120800    \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 32, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32, 4)             204       \n",
      "_________________________________________________________________\n",
      "crf_26 (CRF)                 (None, 32, 4)             16        \n",
      "=================================================================\n",
      "Total params: 6,743,270\n",
      "Trainable params: 6,743,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_street = build_model(raw_vocab_size,target_vocab_size,max_len)\n",
    "model_poi = build_model(raw_vocab_size,target_vocab_size,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:43:58.459828Z",
     "start_time": "2021-03-16T18:43:58.400831Z"
    }
   },
   "outputs": [],
   "source": [
    "model_street.load_weights('street_20200316.h5')\n",
    "model_poi.load_weights('poi_20200316.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:39:09.477710Z",
     "start_time": "2021-03-16T18:39:09.459708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 1, 'I-street': 2, 'B-street': 3, 'PAD': 0}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:49:13.476142Z",
     "start_time": "2021-03-16T18:49:13.449125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>raw_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "      <td>[s., par, 53, sidanegara, 4, cilacap, tengah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "      <td>[angg, per,, baloi, indah, kel., lubuk, baja]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "      <td>[asma, laun,, mand, imog,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "      <td>[ud, agung, rej,, raya, nga, sri, wedari, kara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "      <td>[cut, mutia,, 35, baiturrahman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>toko mbak farid semboro semboro</td>\n",
       "      <td>[toko, mbak, farid, semboro, semboro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>vie - tk. ridho kids, vete 3 cari, 16720 ciawi</td>\n",
       "      <td>[vie, -, tk., ridho, kids,, vete, 3, cari,, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>mart dan roti bakar malabar, nasio,</td>\n",
       "      <td>[mart, dan, roti, bakar, malabar,, nasio,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>graha indah pamulang jl. mujair raya bambu apu...</td>\n",
       "      <td>[graha, indah, pamulang, jl., mujair, raya, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>adi,</td>\n",
       "      <td>[adi,]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        raw_address  \\\n",
       "0          0              s. par 53 sidanegara 4 cilacap tengah   \n",
       "1          1              angg per, baloi indah kel. lubuk baja   \n",
       "2          2                              asma laun, mand imog,   \n",
       "3          3      ud agung rej, raya nga sri wedari karanganyar   \n",
       "4          4                         cut mutia, 35 baiturrahman   \n",
       "...      ...                                                ...   \n",
       "49995  49995                    toko mbak farid semboro semboro   \n",
       "49996  49996     vie - tk. ridho kids, vete 3 cari, 16720 ciawi   \n",
       "49997  49997                mart dan roti bakar malabar, nasio,   \n",
       "49998  49998  graha indah pamulang jl. mujair raya bambu apu...   \n",
       "49999  49999                                               adi,   \n",
       "\n",
       "                                               raw_split  \n",
       "0          [s., par, 53, sidanegara, 4, cilacap, tengah]  \n",
       "1          [angg, per,, baloi, indah, kel., lubuk, baja]  \n",
       "2                             [asma, laun,, mand, imog,]  \n",
       "3      [ud, agung, rej,, raya, nga, sri, wedari, kara...  \n",
       "4                        [cut, mutia,, 35, baiturrahman]  \n",
       "...                                                  ...  \n",
       "49995              [toko, mbak, farid, semboro, semboro]  \n",
       "49996  [vie, -, tk., ridho, kids,, vete, 3, cari,, 16...  \n",
       "49997         [mart, dan, roti, bakar, malabar,, nasio,]  \n",
       "49998  [graha, indah, pamulang, jl., mujair, raya, ba...  \n",
       "49999                                             [adi,]  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:59:40.407355Z",
     "start_time": "2021-03-16T18:59:40.058760Z"
    }
   },
   "outputs": [],
   "source": [
    "test['raw_split'] = test['raw_address'].apply(lambda x: [x1 for x1 in x.split(' ') if x1!='']).values\n",
    "list_x_test = test['raw_split'].values\n",
    "X_test_ori = [[word2idx[w] for w in s] for s in list_x_test]\n",
    "X_test_ori = tf.keras.preprocessing.sequence.pad_sequences(X_test_ori,padding='post',maxlen=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:00:54.465938Z",
     "start_time": "2021-03-16T19:00:54.449939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 440,  394,  399, 3495,    8,  695,   43,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ori[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:59:40.532371Z",
     "start_time": "2021-03-16T18:59:40.518337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[440, 394, 399, 3495, 8, 695, 43]]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:01:10.664867Z",
     "start_time": "2021-03-16T19:01:10.601875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model_street.predict(np.array(word_idx))\n",
    "a = np.argmax(a, axis=-1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:41:07.466540Z",
     "start_time": "2021-03-16T18:39:10.911638Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_street = model_street.predict(X_test_ori)\n",
    "predict_street_final = np.argmax(predict_street, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:45:22.775617Z",
     "start_time": "2021-03-16T18:44:26.337018Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_poi = model_poi.predict(X_test_ori)\n",
    "predict_poi_final = np.argmax(predict_poi, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:47:00.856091Z",
     "start_time": "2021-03-16T18:47:00.840435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict_poi==predict_street).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:51:55.357104Z",
     "start_time": "2021-03-16T18:51:55.345103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_street_final[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:51:58.318142Z",
     "start_time": "2021-03-16T18:51:58.313130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_poi_final[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:45:24.536414Z",
     "start_time": "2021-03-16T18:45:24.529383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_street_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T18:45:25.020586Z",
     "start_time": "2021-03-16T18:45:24.857590Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_address_split_test = test['raw_address'].apply(lambda x: np.array(x.split(' '))).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:01:53.397080Z",
     "start_time": "2021-03-16T19:01:53.378052Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(raw_address_split_test[0])\n",
    "# print(' '.join(raw_address_split_test[0][np.argwhere(predict_street_final[0] > 0).reshape(-1)]))\n",
    "# predict_street_final[0][np.argwhere(x > 0.01)]\n",
    "\n",
    "def get_prediction_word(list_x,predict):\n",
    "#     print(list_x,predict)\n",
    "    try:\n",
    "        return ' '.join(np.array(list_x)[np.argwhere(np.array(predict) > 1).reshape(-1)])\n",
    "    except:\n",
    "        print(list_x,predict)\n",
    "        return ' '.join(np.array(list_x)[np.argwhere(np.array(predict) > 1).reshape(-1)[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:03:00.719656Z",
     "start_time": "2021-03-16T19:02:55.683473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_address</th>\n",
       "      <th>raw_address_split</th>\n",
       "      <th>predict_street_raw</th>\n",
       "      <th>predict_poi_raw</th>\n",
       "      <th>predict_street</th>\n",
       "      <th>predict_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "      <td>[s., par, 53, sidanegara, 4, cilacap, tengah]</td>\n",
       "      <td>[3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>s. par</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "      <td>[angg, per,, baloi, indah, kel., lubuk, baja]</td>\n",
       "      <td>[3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>angg per,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "      <td>[asma, laun,, mand, imog,]</td>\n",
       "      <td>[1, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>mand imog,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "      <td>[ud, agung, rej,, raya, nga, sri, wedari, kara...</td>\n",
       "      <td>[1, 1, 1, 3, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>raya nga</td>\n",
       "      <td>ud agung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "      <td>[cut, mutia,, 35, baiturrahman]</td>\n",
       "      <td>[3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>cut mutia,</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     raw_address  \\\n",
       "0          s. par 53 sidanegara 4 cilacap tengah   \n",
       "1          angg per, baloi indah kel. lubuk baja   \n",
       "2                          asma laun, mand imog,   \n",
       "3  ud agung rej, raya nga sri wedari karanganyar   \n",
       "4                     cut mutia, 35 baiturrahman   \n",
       "\n",
       "                                   raw_address_split  \\\n",
       "0      [s., par, 53, sidanegara, 4, cilacap, tengah]   \n",
       "1      [angg, per,, baloi, indah, kel., lubuk, baja]   \n",
       "2                         [asma, laun,, mand, imog,]   \n",
       "3  [ud, agung, rej,, raya, nga, sri, wedari, kara...   \n",
       "4                    [cut, mutia,, 35, baiturrahman]   \n",
       "\n",
       "                                  predict_street_raw  \\\n",
       "0  [3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 1, 1, 3, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     predict_poi_raw predict_street  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         s. par   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...      angg per,   \n",
       "2  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     mand imog,   \n",
       "3  [3, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...       raya nga   \n",
       "4  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     cut mutia,   \n",
       "\n",
       "  predict_poi  \n",
       "0              \n",
       "1              \n",
       "2              \n",
       "3    ud agung  \n",
       "4              "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.DataFrame()\n",
    "final['raw_address'] = test['raw_address'].values\n",
    "final['raw_address_split'] = test['raw_split'].values\n",
    "final['predict_street_raw'] = predict_street_final.tolist()\n",
    "final['predict_poi_raw'] = predict_poi_final.tolist()\n",
    "\n",
    "\n",
    "final['predict_street'] = final[['raw_address_split','predict_street_raw']].apply(lambda x: get_prediction_word(x['raw_address_split'],x['predict_street_raw']), axis=1)\n",
    "final['predict_poi'] = final[['raw_address_split','predict_poi_raw']].apply(lambda x: get_prediction_word(x['raw_address_split'],x['predict_poi_raw']), axis=1)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:03:00.735643Z",
     "start_time": "2021-03-16T19:03:00.721666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/angg per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laundry/mand imogiri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rejeki/raya ngawi-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/cut mutia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   POI/street\n",
       "0   0                            /\n",
       "1   1                    /angg per\n",
       "2   2    asma laundry/mand imogiri\n",
       "3   3  ud agung rejeki/raya ngawi-\n",
       "4   4                   /cut mutia"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:03:00.799643Z",
     "start_time": "2021-03-16T19:03:00.738644Z"
    }
   },
   "outputs": [],
   "source": [
    "final['final_predict'] = final['predict_poi']+'/'+final['predict_street']\n",
    "final['final_predict'] = final['final_predict'].apply(lambda x: x.strip())\n",
    "final = final.reset_index().rename(columns={'index':'id','final_predict':'POI/street'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:03:00.831680Z",
     "start_time": "2021-03-16T19:03:00.801644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>raw_address_split</th>\n",
       "      <th>predict_street_raw</th>\n",
       "      <th>predict_poi_raw</th>\n",
       "      <th>predict_street</th>\n",
       "      <th>predict_poi</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "      <td>[s., par, 53, sidanegara, 4, cilacap, tengah]</td>\n",
       "      <td>[3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>s. par</td>\n",
       "      <td></td>\n",
       "      <td>/s. par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "      <td>[angg, per,, baloi, indah, kel., lubuk, baja]</td>\n",
       "      <td>[3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>angg per,</td>\n",
       "      <td></td>\n",
       "      <td>/angg per,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "      <td>[asma, laun,, mand, imog,]</td>\n",
       "      <td>[1, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>mand imog,</td>\n",
       "      <td></td>\n",
       "      <td>/mand imog,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "      <td>[ud, agung, rej,, raya, nga, sri, wedari, kara...</td>\n",
       "      <td>[1, 1, 1, 3, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>raya nga</td>\n",
       "      <td>ud agung</td>\n",
       "      <td>ud agung/raya nga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "      <td>[cut, mutia,, 35, baiturrahman]</td>\n",
       "      <td>[3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>cut mutia,</td>\n",
       "      <td></td>\n",
       "      <td>/cut mutia,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    raw_address  \\\n",
       "0   0          s. par 53 sidanegara 4 cilacap tengah   \n",
       "1   1          angg per, baloi indah kel. lubuk baja   \n",
       "2   2                          asma laun, mand imog,   \n",
       "3   3  ud agung rej, raya nga sri wedari karanganyar   \n",
       "4   4                     cut mutia, 35 baiturrahman   \n",
       "\n",
       "                                   raw_address_split  \\\n",
       "0      [s., par, 53, sidanegara, 4, cilacap, tengah]   \n",
       "1      [angg, per,, baloi, indah, kel., lubuk, baja]   \n",
       "2                         [asma, laun,, mand, imog,]   \n",
       "3  [ud, agung, rej,, raya, nga, sri, wedari, kara...   \n",
       "4                    [cut, mutia,, 35, baiturrahman]   \n",
       "\n",
       "                                  predict_street_raw  \\\n",
       "0  [3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 1, 1, 3, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     predict_poi_raw predict_street  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...         s. par   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...      angg per,   \n",
       "2  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     mand imog,   \n",
       "3  [3, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...       raya nga   \n",
       "4  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     cut mutia,   \n",
       "\n",
       "  predict_poi         POI/street  \n",
       "0                        /s. par  \n",
       "1                     /angg per,  \n",
       "2                    /mand imog,  \n",
       "3    ud agung  ud agung/raya nga  \n",
       "4                    /cut mutia,  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:03:13.591958Z",
     "start_time": "2021-03-16T19:03:13.569925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/s. par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/angg per,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/mand imog,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung/raya nga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/cut mutia,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         POI/street\n",
       "0   0            /s. par\n",
       "1   1         /angg per,\n",
       "2   2        /mand imog,\n",
       "3   3  ud agung/raya nga\n",
       "4   4        /cut mutia,"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = final[['id','POI/street']]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T19:03:21.894558Z",
     "start_time": "2021-03-16T19:03:21.817563Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission_20210316.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Shopee_NER",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
